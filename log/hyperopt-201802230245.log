
[2018-02-23 02:46:05,015] INFO: tpe_transform took 0.003955 seconds
[2018-02-23 02:46:05,015] INFO: TPE using 0 trials
[2018-02-23 02:46:05,016] INFO:       MAX_NUM_BIGRAMS: 50000
[2018-02-23 02:46:05,016] INFO:       MAX_NUM_BRANDS: 4809
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_CATEGORIES: 1289
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_CATEGORIES_LST: (12, 115, 871)
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_CONDITIONS: 5
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_SHIPPINGS: 2
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_SUBWORDS: 20000
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_TRIGRAMS: 50000
[2018-02-23 02:46:05,017] INFO:       MAX_NUM_WORDS: 80000
[2018-02-23 02:46:05,017] INFO:       NUM_VARS_DIM: 3
[2018-02-23 02:46:05,017] INFO:       RUNNING_MODE: validation
[2018-02-23 02:46:05,017] INFO:       attend_method: ave
[2018-02-23 02:46:05,017] INFO:       base_lr: 1e-05
[2018-02-23 02:46:05,017] INFO:       batch_size_inference: 1024
[2018-02-23 02:46:05,017] INFO:       batch_size_train: 512
[2018-02-23 02:46:05,017] INFO:       beta1: 0.975
[2018-02-23 02:46:05,017] INFO:       beta2: 0.999
[2018-02-23 02:46:05,017] INFO:       cnn_filter_sizes: (2, 3)
[2018-02-23 02:46:05,017] INFO:       cnn_num_filters: 16
[2018-02-23 02:46:05,017] INFO:       cnn_timedistributed: False
[2018-02-23 02:46:05,017] INFO:       embedding_dim: 250
[2018-02-23 02:46:05,018] INFO:       embedding_dropout: 0.0
[2018-02-23 02:46:05,018] INFO:       embedding_mask_zero: False
[2018-02-23 02:46:05,018] INFO:       embedding_mask_zero_subword: False
[2018-02-23 02:46:05,018] INFO:       enable_deep: True
[2018-02-23 02:46:05,018] INFO:       enable_fm_first_order: True
[2018-02-23 02:46:05,018] INFO:       enable_fm_higher_order: False
[2018-02-23 02:46:05,018] INFO:       enable_fm_second_order: True
[2018-02-23 02:46:05,018] INFO:       enable_snapshot_ensemble: True
[2018-02-23 02:46:05,018] INFO:       encode_method: fasttext
[2018-02-23 02:46:05,018] INFO:       epoch: 4
[2018-02-23 02:46:05,018] INFO:       eval_every_num_update: 1000
[2018-02-23 02:46:05,018] INFO:       fc_dim: 64
[2018-02-23 02:46:05,018] INFO:       fc_dropout: 0.0
[2018-02-23 02:46:05,018] INFO:       fc_type: fc
[2018-02-23 02:46:05,018] INFO:       item_condition_size: 5
[2018-02-23 02:46:05,018] INFO:       lr_decay_each_epoch_cosine: 0.5
[2018-02-23 02:46:05,018] INFO:       lr_decay_each_epoch_exp: 0.9
[2018-02-23 02:46:05,018] INFO:       lr_jump_exp: True
[2018-02-23 02:46:05,018] INFO:       lr_jump_rate: 1.0
[2018-02-23 02:46:05,018] INFO:       lr_schedule: cosine_decay_restarts
[2018-02-23 02:46:05,018] INFO:       max_lr_cosine: 0.005
[2018-02-23 02:46:05,019] INFO:       max_lr_exp: 0.005
[2018-02-23 02:46:05,019] INFO:       max_sequence_length_category_name: 10
[2018-02-23 02:46:05,019] INFO:       max_sequence_length_item_desc: 50
[2018-02-23 02:46:05,019] INFO:       max_sequence_length_item_desc_subword: 45
[2018-02-23 02:46:05,019] INFO:       max_sequence_length_name: 10
[2018-02-23 02:46:05,019] INFO:       max_snapshot_num: 14
[2018-02-23 02:46:05,019] INFO:       model_dir: ./weights
[2018-02-23 02:46:05,019] INFO:       n_folds: 1
[2018-02-23 02:46:05,019] INFO:       n_runs: 2
[2018-02-23 02:46:05,019] INFO:       num_cycle_each_epoch: 8
[2018-02-23 02:46:05,019] INFO:       num_vars_size: 3
[2018-02-23 02:46:05,019] INFO:       optimizer_clipnorm: 1.0
[2018-02-23 02:46:05,019] INFO:       optimizer_type: nadam
[2018-02-23 02:46:05,019] INFO:       pad_sequences_padding: post
[2018-02-23 02:46:05,019] INFO:       pad_sequences_truncating: post
[2018-02-23 02:46:05,019] INFO:       random_seed: 2018
[2018-02-23 02:46:05,019] INFO:       rnn_cell_type: gru
[2018-02-23 02:46:05,019] INFO:       rnn_num_units: 16
[2018-02-23 02:46:05,019] INFO:       schedule_decay: 0.004
[2018-02-23 02:46:05,019] INFO:       shipping_size: 1
[2018-02-23 02:46:05,020] INFO:       shuffle_with_replacement: False
[2018-02-23 02:46:05,020] INFO:       snapshot_before_restarts: 4
[2018-02-23 02:46:05,020] INFO:       snapshot_every_epoch: 4
[2018-02-23 02:46:05,020] INFO:       snapshot_every_num_cycle: 128
[2018-02-23 02:46:05,020] INFO:       t_mul: 1
[2018-02-23 02:46:05,020] INFO:       use_bigram: True
[2018-02-23 02:46:05,020] INFO:       use_subword: False
[2018-02-23 02:46:05,020] INFO:       use_trigram: True
[2018-02-23 02:46:05,020] INFO:       validation_ratio: 0.4
[2018-02-23 02:46:48,379] INFO: [batch-1] train-rmsle=0.07488, lr=0.00500 [0.6 s]
[2018-02-23 02:46:48,405] INFO: [batch-2] train-rmsle=0.14652, lr=0.00500 [0.7 s]
[2018-02-23 02:46:48,431] INFO: [batch-3] train-rmsle=0.20133, lr=0.00500 [0.7 s]
[2018-02-23 02:46:48,457] INFO: [batch-4] train-rmsle=0.25417, lr=0.00499 [0.7 s]
[2018-02-23 02:46:48,483] INFO: [batch-5] train-rmsle=0.30096, lr=0.00499 [0.8 s]
[2018-02-23 02:46:48,508] INFO: [batch-6] train-rmsle=0.34126, lr=0.00499 [0.8 s]
[2018-02-23 02:46:48,533] INFO: [batch-7] train-rmsle=0.37511, lr=0.00499 [0.8 s]
[2018-02-23 02:46:48,557] INFO: [batch-8] train-rmsle=0.40439, lr=0.00498 [0.8 s]
[2018-02-23 02:46:48,581] INFO: [batch-9] train-rmsle=0.42563, lr=0.00498 [0.8 s]
[2018-02-23 02:46:48,605] INFO: [batch-10] train-rmsle=0.45331, lr=0.00498 [0.9 s]
[2018-02-23 02:46:48,630] INFO: [batch-11] train-rmsle=0.47406, lr=0.00498 [0.9 s]
[2018-02-23 02:46:48,655] INFO: [batch-12] train-rmsle=0.48758, lr=0.00497 [0.9 s]
[2018-02-23 02:46:48,679] INFO: [batch-13] train-rmsle=0.50060, lr=0.00497 [0.9 s]
[2018-02-23 02:46:48,703] INFO: [batch-14] train-rmsle=0.51559, lr=0.00497 [1.0 s]
[2018-02-23 02:46:48,727] INFO: [batch-15] train-rmsle=0.53065, lr=0.00497 [1.0 s]
[2018-02-23 02:46:48,751] INFO: [batch-16] train-rmsle=0.54205, lr=0.00496 [1.0 s]
[2018-02-23 02:46:48,776] INFO: [batch-17] train-rmsle=0.54671, lr=0.00496 [1.0 s]
[2018-02-23 02:46:48,800] INFO: [batch-18] train-rmsle=0.55022, lr=0.00496 [1.1 s]
[2018-02-23 02:46:48,824] INFO: [batch-19] train-rmsle=0.55167, lr=0.00496 [1.1 s]
[2018-02-23 02:46:48,848] INFO: [batch-20] train-rmsle=0.55379, lr=0.00495 [1.1 s]
[2018-02-23 02:46:48,872] INFO: [batch-21] train-rmsle=0.55953, lr=0.00495 [1.1 s]
[2018-02-23 02:46:48,896] INFO: [batch-22] train-rmsle=0.56424, lr=0.00495 [1.2 s]
[2018-02-23 02:46:48,920] INFO: [batch-23] train-rmsle=0.57113, lr=0.00495 [1.2 s]
[2018-02-23 02:46:48,944] INFO: [batch-24] train-rmsle=0.57541, lr=0.00494 [1.2 s]
[2018-02-23 02:46:48,969] INFO: [batch-25] train-rmsle=0.58127, lr=0.00494 [1.2 s]
[2018-02-23 02:46:48,993] INFO: [batch-26] train-rmsle=0.58110, lr=0.00494 [1.3 s]
[2018-02-23 02:46:49,017] INFO: [batch-27] train-rmsle=0.57499, lr=0.00494 [1.3 s]
[2018-02-23 02:46:49,041] INFO: [batch-28] train-rmsle=0.57366, lr=0.00493 [1.3 s]
[2018-02-23 02:46:49,065] INFO: [batch-29] train-rmsle=0.57266, lr=0.00493 [1.3 s]
[2018-02-23 02:46:49,089] INFO: [batch-30] train-rmsle=0.57204, lr=0.00493 [1.4 s]
[2018-02-23 02:46:49,114] INFO: [batch-31] train-rmsle=0.56875, lr=0.00493 [1.4 s]
[2018-02-23 02:46:49,137] INFO: [batch-32] train-rmsle=0.56467, lr=0.00493 [1.4 s]
[2018-02-23 02:46:49,161] INFO: [batch-33] train-rmsle=0.56415, lr=0.00492 [1.4 s]
[2018-02-23 02:46:49,184] INFO: [batch-34] train-rmsle=0.55902, lr=0.00492 [1.5 s]
[2018-02-23 02:46:49,209] INFO: [batch-35] train-rmsle=0.55961, lr=0.00492 [1.5 s]
[2018-02-23 02:46:49,233] INFO: [batch-36] train-rmsle=0.55641, lr=0.00492 [1.5 s]
[2018-02-23 02:46:49,256] INFO: [batch-37] train-rmsle=0.55547, lr=0.00491 [1.5 s]
[2018-02-23 02:46:49,279] INFO: [batch-38] train-rmsle=0.55164, lr=0.00491 [1.5 s]
[2018-02-23 02:46:49,303] INFO: [batch-39] train-rmsle=0.55187, lr=0.00491 [1.6 s]
[2018-02-23 02:46:49,328] INFO: [batch-40] train-rmsle=0.55215, lr=0.00491 [1.6 s]